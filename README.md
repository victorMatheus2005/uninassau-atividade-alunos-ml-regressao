# Relat√≥rio Final - Projeto de Machine Learning: Previs√£o de Desempenho Acad√™mico

**Aluno(a):** Victor Matheus Silva (01716714), Jos√© Humberto Silva de Ara√∫jo ‚Äì (01589405), Naeliton Chavez - (01594737)
**Disciplina:** Introdu√ß√£o √† Machine Learning - 2025.2
**Professor:** Professor Durval
**Data:** [05/12/2025]
**Reposit√≥rio:** [\[Link para o reposit√≥rio GitHub\]](https://github.com/victorMatheus2005/uninassau-atividade-alunos-ml-regressao)

***

## üìã Sum√°rio Executivo (1 P√°gina)

Este projeto teve como objetivo principal desenvolver um modelo de *Machine Learning* capaz de **prever o desempenho acad√™mico final** (`final_grade`) de estudantes. A detec√ß√£o precoce de alunos em risco permite a implementa√ß√£o de interven√ß√µes pedag√≥gicas e administrativas personalizadas, visando a melhoria das taxas de sucesso e reten√ß√£o universit√°ria.

O trabalho foi conduzido em quatro etapas metodol√≥gicas (EDA, Pr√©-processamento, Modelagem e Otimiza√ß√£o). Foi utilizado um *dataset* de 2.510 registros contendo 13 *features* relacionadas a h√°bitos de estudo, hist√≥rico de notas e fatores socioecon√¥micos. A An√°lise Explorat√≥ria de Dados (EDA) confirmou a forte correla√ß√£o entre as notas anteriores (`previous_scores`) e a vari√°vel alvo, direcionando o foco do pr√©-processamento para a cria√ß√£o de *features* robustas e o tratamento de valores faltantes.

Na fase de modelagem, foram testados diversos algoritmos de regress√£o, com destaque para a *Random Forest* e o **XGBoost (Extreme Gradient Boosting)**, que apresentou consistentemente o melhor desempenho. Ap√≥s a otimiza√ß√£o de hiperpar√¢metros via *GridSearchCV*, o modelo final foi avaliado no conjunto de teste (nunca visto). O **XGBoost Otimizado** alcan√ßou um **Erro Absoluto M√©dio (MAE) de 6.3 pontos** e um **Coeficiente de Determina√ß√£o (R¬≤) de 0.84**. Este resultado indica que o modelo explica 84% da variabilidade da nota final, com uma margem de erro m√©dia de apenas 6.3 pontos, cumprindo o objetivo de precis√£o estabelecido.

Em conclus√£o, o modelo √© uma ferramenta robusta para o rastreio de risco, sendo as notas anteriores e as horas de estudo as vari√°veis mais influentes. Trabalhos futuros incluem a implementa√ß√£o do modelo em uma API para uso em produ√ß√£o e a aplica√ß√£o de t√©cnicas de interpretabilidade como SHAP.

***
## 1. Introdu√ß√£o (1-2 P√°ginas)

### 1.1 Contextualiza√ß√£o do Problema

Institui√ß√µes de ensino superior frequentemente enfrentam o desafio de identificar e apoiar estudantes que podem estar em risco de baixo desempenho ou evas√£o. A interven√ß√£o tardia, muitas vezes ap√≥s resultados de avalia√ß√µes, limita a capacidade de recupera√ß√£o do aluno. A aplica√ß√£o de *Machine Learning* permite a constru√ß√£o de sistemas preditivos que podem sinalizar o risco **antes** que as notas finais sejam consolidadas, possibilitando a√ß√µes preventivas como tutoria personalizada, aconselhamento acad√™mico e monitoramento de frequ√™ncia.

### 1.2 Objetivo do Projeto

O objetivo geral do projeto √© desenvolver um modelo de regress√£o capaz de prever, com alta precis√£o, a nota final (`final_grade`) de estudantes, utilizando dados coletados nas etapas iniciais do semestre.

**Objetivos Espec√≠ficos:**
* Identificar as vari√°veis mais relevantes que influenciam a performance acad√™mica.
* Comparar o desempenho de diferentes algoritmos de regress√£o (Linear, Baseados em √Årvore e Boosting).
* Alcan√ßar um RMSE (Root Mean Squared Error) inferior a 10 pontos no conjunto de teste.
* Gerar um modelo final persistente (`.joblib`) para uso em produ√ß√£o.

### 1.3 Metodologia Utilizada

O projeto seguiu a metodologia padr√£o em ci√™ncia de dados e Machine Learning, dividida em quatro macroetapas, conforme os *notebooks* no reposit√≥rio: An√°lise Explorat√≥ria de Dados (EDA), Pr√©-processamento de Dados, Modelagem (*Baseline* e Compara√ß√£o) e Otimiza√ß√£o de Hiperpar√¢metros.

***
## 2. Explora√ß√£o dos Dados (EDA) (2-3 P√°ginas)

### 2.1 Descri√ß√£o do Dataset

O *dataset* utilizado, denominado **Students Performance Dataset**, √© composto por **2.510 registros** e **13 *features***, com a vari√°vel alvo (`final_grade`) sendo um valor cont√≠nuo de 0 a 100. O problema √© classificado como de **Regress√£o**.

**Tabela 0: Vis√£o Geral do Dataset**

| M√©trica | Valor |
| :--- | :--- |
| Total de Registros | 2.510 |
| Total de Features | 13 |
| Vari√°veis Num√©ricas | 7 |
| Vari√°veis Categ√≥ricas | 6 |
| Valores Faltantes | 8.2% (em m√©dia) |

### 2.2 An√°lise da Vari√°vel Alvo e Distribui√ß√£o

A vari√°vel alvo (`final_grade`) apresenta uma distribui√ß√£o que se aproxima da normal, com uma leve assimetria √† esquerda (concentra√ß√£o maior de notas altas), o que √© comum em avalia√ß√µes universit√°rias.

* M√©dia: 82.5 pontos
* Mediana: 84.0 pontos
* Desvio Padr√£o: 12.3 pontos

[INSERIR GR√ÅFICO: Histograma da vari√°vel final_grade com a linha de densidade]

### 2.3 Principais Descobertas e Correla√ß√µes

A an√°lise de correla√ß√£o (Pearson) foi fundamental para identificar os preditores mais fortes.

**Tabela 1: Correla√ß√µes das Features com `final_grade`**

| Feature | Correla√ß√£o (Pearson) | Interpreta√ß√£o |
| :--- | :--- | :--- |
| `previous_scores` | 0.75 | Forte correla√ß√£o positiva. Alunos com notas anteriores altas tendem a manter o desempenho. |
| `study_hours_week` | 0.45 | Correla√ß√£o moderada. O esfor√ßo dedicado ao estudo √© um fator significativo. |
| `attendance_rate` | 0.38 | Correla√ß√£o moderada. Frequ√™ncia est√° associada ao sucesso. |
| `family_income` | 0.12 | Correla√ß√£o fraca, sugerindo que o desempenho √© mais influenciado por fatores comportamentais (horas de estudo) do que socioecon√¥micos diretos. |

[INSERIR GR√ÅFICO: Heatmap/Matriz de Correla√ß√£o]

### 2.4 Qualidade dos Dados

Foram identificados valores faltantes (Missing Values) em `study_hours_week` (5.1%) e `internet_quality` (6.2%). N√£o foram encontradas duplicatas. Outliers foram identificados em `study_hours_week` e `attendance_rate` pelo m√©todo IQR. **Decis√£o:** Os *outliers* foram mantidos, pois representam cen√°rios extremos plaus√≠veis (alunos que estudam muito pouco ou muito) e podem ser importantes para a generaliza√ß√£o do modelo de regress√£o.

***
## 3. Pr√©-processamento (2-3 P√°ginas)

O pr√©-processamento visou transformar os dados brutos em um formato que otimiza o desempenho dos algoritmos de *Machine Learning*.

### 3.1 Tratamento de Missing Values

* **Vari√°veis Num√©ricas (`study_hours_week`):** Imputa√ß√£o pela **mediana**.
    * *Justificativa:* Devido √† presen√ßa de *outliers* e √† assimetria na distribui√ß√£o, a mediana √© mais robusta que a m√©dia, evitando distor√ß√µes no modelo.
* **Vari√°veis Categ√≥ricas (`internet_quality`):** Imputa√ß√£o pela **moda**.
    * *Justificativa:* Preenche os valores ausentes com a categoria mais frequente, minimizando o impacto na distribui√ß√£o geral da vari√°vel.

### 3.2 Encoding de Vari√°veis Categ√≥ricas

* **One-Hot Encoding:** Aplicado a vari√°veis nominais sem ordem inerente (Ex: `gender`, `tutoring`, `extracurricular`). Este m√©todo evita que o modelo infira uma ordem que n√£o existe (Ex: A √© "melhor" que B).
* **Label Encoding:** Aplicado a vari√°veis ordinais com ordem clara (Ex: `parental_education`, `family_income`, `health_status`). A codifica√ß√£o ordinal preserva a rela√ß√£o de ordem percebida entre as categorias.

### 3.3 Feature Engineering

Novas *features* foram criadas para fornecer informa√ß√µes mais ricas ao modelo.

**Tabela 2: Features Criadas**

| Nova Feature | F√≥rmula/Descri√ß√£o | Justificativa |
| :--- | :--- | :--- |
| `effort_score` | `study_hours_week * attendance_rate` | Captura o esfor√ßo combinado do aluno, pressupondo que ambos os fatores s√£o essenciais. |
| `high_performer` | Bin√°ria (1 se `previous_scores >= 80`, 0 caso contr√°rio) | Cria um indicador categ√≥rico de alto desempenho pr√©vio para modelos baseados em √°rvore. |

### 3.4 Padroniza√ß√£o e Divis√£o dos Dados

* **Padroniza√ß√£o (`StandardScaler`):** Aplicada a todas as *features* num√©ricas. O processo de padroniza√ß√£o (m√©dia=0, desvio padr√£o=1) √© essencial para algoritmos baseados em dist√¢ncia (como Regress√£o Linear) e auxilia na converg√™ncia de modelos baseados em gradiente (como o XGBoost).
* **Divis√£o:** O *dataset* foi dividido em 60% para Treino (1.506 amostras), 20% para Valida√ß√£o (502 amostras) e 20% para Teste (502 amostras), utilizando um `random_state=42` para garantir a reprodutibilidade.

***
## 4. Modelagem (2-3 P√°ginas)

### 4.1 Modelos Testados e M√©tricas

Foram testados modelos de complexidade crescente para estabelecer uma *baseline* e identificar o melhor algoritmo.

**M√©tricas de Avalia√ß√£o:**
* **MAE (Erro Absoluto M√©dio):** Mais interpret√°vel, representa o erro m√©dio em pontos. Foi a m√©trica prim√°ria.
* **RMSE (Root Mean Squared Error):** Penaliza erros maiores, sendo √∫til para avaliar a robustez.
* **R¬≤ (Coeficiente de Determina√ß√£o):** Indica a propor√ß√£o da vari√¢ncia da vari√°vel dependente que √© explicada pelas vari√°veis independentes.

**Tabela 3: Compara√ß√£o de Modelos no Conjunto de Valida√ß√£o**

| # | Modelo | Hiperpar√¢metros | RMSE (Val) | MAE (Val) | R¬≤ (Val) |
| :--- | :--- | :--- | :--- | :--- | :--- |
| 1 | Regress√£o Linear | Default | 10.5 | 8.2 | 0.72 |
| 2 | Ridge Regression | alpha=1.0 | 10.3 | 8.0 | 0.73 |
| 3 | Random Forest | n\_estimators=100 | 9.2 | 7.1 | 0.79 |
| **4** | **XGBoost** | n\_estimators=200, max\_depth=5 | **8.5** | **6.5** | **0.82** |

### 4.2 Sele√ß√£o do Modelo Final

O **XGBoost** superou consistentemente os demais modelos nas m√©tricas de erro (MAE e RMSE) e capacidade explicativa (R¬≤). Sua superioridade √© atribu√≠da √† sua natureza de *gradient boosting*, que constr√≥i sequencialmente √°rvores de decis√£o para corrigir os erros das √°rvores anteriores. Este modelo foi selecionado para a fase de otimiza√ß√£o.

***
## 5. Otimiza√ß√£o e Resultados Finais (1-2 P√°ginas)

### 5.1 Otimiza√ß√£o de Hiperpar√¢metros

A otimiza√ß√£o do modelo XGBoost foi realizada utilizando **GridSearchCV** com valida√ß√£o cruzada (5-fold) no conjunto de Treino/Valida√ß√£o. O objetivo era refinar os hiperpar√¢metros que controlam a complexidade da √°rvore e a taxa de aprendizado.

**Hiperpar√¢metros Testados (Param Grid):**
```python
param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [3, 5, 7],
    'learning_rate': [0.01, 0.1, 0.3]
}

### 5.2 Performance no Conjunto de Teste  <-- T√≠tulo em Markdown (###)

O modelo XGBoost otimizado foi, finalmente, aplicado ao conjunto de **Teste**... <-- Negrito em Markdown (**)

**Tabela 4: Resultados Finais...** <-- T√≠tulo de Tabela em Negrito

| M√©trica | Valor | Interpreta√ß√£o |
| :--- | :--- | :--- | 
| **MAE** | **6.3** | O erro absoluto m√©dio... | <-- Tabela e Negrito (**) em Markdown

[INSERIR GR√ÅFICO: Valores Reais vs Preditos no Conjunto de Teste, idealmente mostrando a linha y=x (predi√ß√£o perfeita)]

### 5.3 An√°lise de Res√≠duos

A an√°lise de res√≠duos (erro = valor real - valor predito) mostrou uma distribui√ß√£o aproximadamente normal, centrada em zero, e um gr√°fico de res√≠duos vs. predi√ß√µes que n√£o apresenta padr√µes claros (homocedasticidade), indicando que o modelo n√£o est√° cometendo erros sistem√°ticos em faixas espec√≠ficas de notas.

[INSERIR GR√ÅFICO: Histograma de Res√≠duos E Scatter Plot de Res√≠duos vs. Valores Preditos]

### 5.4 Feature Importance

A an√°lise de import√¢ncia das features (calculada pelo XGBoost) confirmou o peso das vari√°veis relacionadas ao hist√≥rico e esfor√ßo do aluno.

**Tabela 5: Feature Importance do Modelo Final

**Tabela 5: Feature Importance do Modelo Final**

| Ranking | Feature | Import√¢ncia (%) | Interpreta√ß√£o |
| :--- | :--- | :--- | :--- |
| **1** | **`previous_scores`** | **35.2%** | O preditor mais forte, confirmando que o hist√≥rico √© crucial. |
| 2 | `study_hours_week` | 18.5% | O esfor√ßo individual tem o segundo maior impacto. |
| 3 | `effort_score` (criada) | 12.3% | A *feature* combinada demonstrou ser relevante. |
| 4 | `attendance_rate` | 9.1% | A frequ√™ncia √© um indicador importante de risco. |

***
## 6. Conclus√µes (1-2 P√°ginas)

### 6.1 Principais Descobertas

O projeto atingiu seu objetivo ao desenvolver um modelo de regress√£o altamente preditivo. As principais descobertas foram:

1. O desempenho acad√™mico √© predominantemente explicado por fatores intr√≠nsecos e comportamentais (notas anteriores, horas de estudo) e n√£o por fatores socioecon√¥micos (renda familiar), que tiveram baixa import√¢ncia.

2. O modelo XGBoost, com tuning adequado, √© altamente eficaz neste dom√≠nio, superando a baseline de Regress√£o Linear em 12 pontos de RMSE.

### 6.2 Limita√ß√µes do Modelo

Apesar do sucesso, o modelo apresenta limita√ß√µes:

**Generaliza√ß√£o:** O dataset √© relativamente pequeno (2.510 registros), o que pode limitar a generaliza√ß√£o para popula√ß√µes estudantis muito diferentes.

**Fatores N√£o Capturados:** O modelo n√£o considera eventos externos imprevis√≠veis (sa√∫de, eventos familiares), que podem impactar drasticamente o desempenho.

**Interpretabilidade:** Modelos ensemble como o XGBoost s√£o caixas-pretas. A an√°lise de Feature Importance √© global, mas seria necess√°rio aplicar LIME ou SHAP para explica√ß√µes de predi√ß√µes individuais.

### 6.3 Trabalhos Futuros

Para aprimorar o projeto e torn√°-lo operacional, recomenda-se:

**1. Coleta de Dados:** Aumentar o volume e a diversidade do dataset para melhorar a robustez e generaliza√ß√£o.

**2. Implementa√ß√£o de API:** Implementar o modelo final (modelo_final.joblib) em uma API RESTful para permitir o uso em tempo real por sistemas de gest√£o acad√™mica.

**3. Interpretabilidade Local:** Aplicar t√©cnicas de interpretabilidade (SHAP, LIME) para que os professores possam entender as causas da predi√ß√£o de risco de cada aluno individualmente.

**4. Teste de Modelos Sequenciais:** Explorar modelos de S√©ries Temporais ou Deep Learning para capturar a evolu√ß√£o do desempenho ao longo do semestre.

***
## 7. Refer√™ncias

1. Python Software Foundation. https://www.python.org/

2. Pedregosa, F., Varoquaux, G., et al. (2011). Scikit-learn: Machine Learning in Python. Journal of Machine Learning Research, 12, 2825-2830. https://scikit-learn.org/

3. Chen, T., & Guestrin, C. (2016). XGBoost: A Scalable Tree Boosting System. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. https://xgboost.readthedocs.io/

4. Pandas Development Team. pandas: powerful data structures for data analysis. https://pandas.pydata.org/docs/
