# üìö Boas Pr√°ticas para o Projeto de Machine Learning

Este documento cont√©m orienta√ß√µes e melhores pr√°ticas para garantir que seu projeto seja bem-sucedido, organizado e profissional.

---

## üéØ Organiza√ß√£o Geral

### 1. Mantenha o C√≥digo Limpo e Organizado

‚úÖ **BOM:**
```python
# Carregar dados e realizar an√°lise explorat√≥ria inicial
df = pd.read_csv('data/raw/students_performance.csv')
print(f"Dataset shape: {df.shape}")
print(f"Missing values:\n{df.isnull().sum()}")
```

‚ùå **RUIM:**
```python
df=pd.read_csv('data/raw/students_performance.csv')
print(df.shape)
print(df.isnull().sum())
# c√≥digo desorganizado, sem coment√°rios
```

### 2. Use Coment√°rios Descritivos

‚úÖ **BOM:**
```python
# Identificar outliers usando m√©todo IQR (Interquartile Range)
# Valores abaixo de Q1 - 1.5*IQR ou acima de Q3 + 1.5*IQR s√£o considerados outliers
Q1 = df['study_hours_week'].quantile(0.25)
Q3 = df['study_hours_week'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['study_hours_week'] < Q1 - 1.5*IQR) |
              (df['study_hours_week'] > Q3 + 1.5*IQR)]
```

‚ùå **RUIM:**
```python
# outliers
Q1 = df['study_hours_week'].quantile(0.25)
Q3 = df['study_hours_week'].quantile(0.75)
IQR = Q3 - Q1
outliers = df[(df['study_hours_week'] < Q1 - 1.5*IQR) | (df['study_hours_week'] > Q3 + 1.5*IQR)]
```

### 3. Divida o C√≥digo em Se√ß√µes L√≥gicas

Use markdown headers nos notebooks Jupyter:

```markdown
# 1. Importa√ß√£o de Bibliotecas

# 2. Carregamento de Dados

# 3. An√°lise Explorat√≥ria
## 3.1 Valores Faltantes
## 3.2 Distribui√ß√£o da Vari√°vel Alvo
## 3.3 Correla√ß√µes

# 4. Conclus√µes
```

---

## üìä An√°lise Explorat√≥ria de Dados (EDA)

### 1. Sempre Verifique os Dados Primeiro

```python
# Inspe√ß√£o inicial obrigat√≥ria
df.head()
df.info()
df.describe()
df.isnull().sum()
df.duplicated().sum()
```

### 2. Visualiza√ß√µes Devem Ser Informativas

‚úÖ **BOM:**
```python
import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 6))
sns.histplot(df['final_grade'], kde=True, bins=30)
plt.title('Distribui√ß√£o das Notas Finais', fontsize=14, fontweight='bold')
plt.xlabel('Nota Final', fontsize=12)
plt.ylabel('Frequ√™ncia', fontsize=12)
plt.axvline(df['final_grade'].mean(), color='red', linestyle='--', label=f'M√©dia: {df["final_grade"].mean():.2f}')
plt.legend()
plt.grid(alpha=0.3)
plt.show()
```

‚ùå **RUIM:**
```python
df['final_grade'].hist()
plt.show()
```

### 3. Documente Suas Descobertas

Ap√≥s cada visualiza√ß√£o ou an√°lise, adicione c√©lulas markdown explicando:
- O que voc√™ est√° analisando
- O que voc√™ encontrou
- Por que isso √© importante

**Exemplo:**
```markdown
### An√°lise de Correla√ß√£o

A matriz de correla√ß√£o mostra que:
- `previous_scores` tem a maior correla√ß√£o com `final_grade` (r=0.75)
- `study_hours_week` tem correla√ß√£o moderada (r=0.45)
- `sleep_hours` tem correla√ß√£o fraca (r=0.12)

**Conclus√£o:** Notas anteriores s√£o o melhor preditor, seguidas por horas de estudo.
```

---

## üîß Pr√©-processamento de Dados

### 1. Tratamento de Valores Faltantes

‚úÖ **BOM:** Documente a estrat√©gia escolhida
```python
# Estrat√©gia de imputa√ß√£o:
# - Num√©ricas: mediana (mais robusta a outliers)
# - Categ√≥ricas: moda (valor mais frequente)

from sklearn.impute import SimpleImputer

# Imputar vari√°veis num√©ricas
num_imputer = SimpleImputer(strategy='median')
df[num_cols] = num_imputer.fit_transform(df[num_cols])

# Imputar vari√°veis categ√≥ricas
cat_imputer = SimpleImputer(strategy='most_frequent')
df[cat_cols] = cat_imputer.fit_transform(df[cat_cols])

print(f"‚úÖ Valores faltantes ap√≥s imputa√ß√£o: {df.isnull().sum().sum()}")
```

‚ùå **RUIM:** Deletar linhas sem justificativa
```python
df = df.dropna()  # Perde muitos dados!
```

### 2. Encoding de Vari√°veis Categ√≥ricas

```python
# One-Hot Encoding para vari√°veis nominais (sem ordem)
df = pd.get_dummies(df, columns=['gender', 'tutoring', 'extracurricular'], drop_first=True)

# Label Encoding para vari√°veis ordinais (com ordem)
from sklearn.preprocessing import LabelEncoder

# Criar mapeamento manual para preservar ordem
education_map = {
    'high_school': 0,
    'bachelor': 1,
    'master': 2,
    'doctorate': 3
}
df['parental_education'] = df['parental_education'].map(education_map)
```

### 3. Feature Engineering

Crie features novas que possam melhorar o modelo:

```python
# Criar feature de "esfor√ßo total" (horas de estudo * frequ√™ncia)
df['effort_score'] = df['study_hours_week'] * (df['attendance_rate'] / 100)

# Criar categoria de "alto desempenho anterior"
df['high_previous_performer'] = (df['previous_scores'] >= 80).astype(int)

# Criar intera√ß√£o entre vari√°veis
df['study_x_tutoring'] = df['study_hours_week'] * df['tutoring_Yes']
```

---

## ü§ñ Modelagem

### 1. Sempre Divida os Dados Corretamente

```python
from sklearn.model_selection import train_test_split

# Separar features (X) e target (y)
X = df.drop('final_grade', axis=1)
y = df['final_grade']

# Divis√£o 60% treino, 20% valida√ß√£o, 20% teste
X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.25, random_state=42)

print(f"Treino: {X_train.shape[0]} amostras")
print(f"Valida√ß√£o: {X_val.shape[0]} amostras")
print(f"Teste: {X_test.shape[0]} amostras")
```

### 2. Normalize/Padronize Apenas Ap√≥s o Split

‚ùå **RUIM:** Normalizar antes do split (data leakage!)
```python
X = scaler.fit_transform(X)  # ERRADO!
X_train, X_test = train_test_split(X, y)
```

‚úÖ **BOM:** Fit no treino, transform em valida√ß√£o/teste
```python
from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)  # Apenas transform!
X_test_scaled = scaler.transform(X_test)  # Apenas transform!
```

### 3. Avalie M√∫ltiplas M√©tricas

```python
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import numpy as np

def evaluate_model(y_true, y_pred, model_name="Model"):
    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)
    mae = mean_absolute_error(y_true, y_pred)
    r2 = r2_score(y_true, y_pred)

    print(f"\n{'='*50}")
    print(f"{model_name} - Performance Metrics")
    print(f"{'='*50}")
    print(f"RMSE: {rmse:.4f}")
    print(f"MAE:  {mae:.4f}")
    print(f"R¬≤:   {r2:.4f}")
    print(f"{'='*50}")

    return {'rmse': rmse, 'mae': mae, 'r2': r2}

# Usar
results = evaluate_model(y_val, y_pred, "Linear Regression")
```

### 4. Compare Modelos de Forma Organizada

```python
import pandas as pd

# Dicion√°rio para armazenar resultados
results_dict = {}

# Treinar e avaliar m√∫ltiplos modelos
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from xgboost import XGBRegressor

models = {
    'Linear Regression': LinearRegression(),
    'Ridge': Ridge(),
    'Lasso': Lasso(),
    'Random Forest': RandomForestRegressor(random_state=42),
    'XGBoost': XGBRegressor(random_state=42)
}

for name, model in models.items():
    model.fit(X_train_scaled, y_train)
    y_pred = model.predict(X_val_scaled)
    results_dict[name] = evaluate_model(y_val, y_pred, name)

# Criar DataFrame de compara√ß√£o
results_df = pd.DataFrame(results_dict).T
results_df = results_df.sort_values('rmse')
print("\nüìä Compara√ß√£o de Modelos:")
print(results_df)
```

---

## üîç Valida√ß√£o e Interpreta√ß√£o

### 1. An√°lise de Res√≠duos

```python
import matplotlib.pyplot as plt

# Calcular res√≠duos
residuals = y_val - y_pred

# Plot de res√≠duos
fig, axes = plt.subplots(1, 2, figsize=(14, 5))

# Res√≠duos vs Predi√ß√µes
axes[0].scatter(y_pred, residuals, alpha=0.5)
axes[0].axhline(0, color='red', linestyle='--')
axes[0].set_xlabel('Valores Preditos')
axes[0].set_ylabel('Res√≠duos')
axes[0].set_title('Res√≠duos vs Predi√ß√µes')
axes[0].grid(alpha=0.3)

# Distribui√ß√£o dos res√≠duos
axes[1].hist(residuals, bins=30, edgecolor='black')
axes[1].set_xlabel('Res√≠duos')
axes[1].set_ylabel('Frequ√™ncia')
axes[1].set_title('Distribui√ß√£o dos Res√≠duos')
axes[1].grid(alpha=0.3)

plt.tight_layout()
plt.show()
```

### 2. Feature Importance

```python
# Para modelos baseados em √°rvores
feature_importance = pd.DataFrame({
    'feature': X_train.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

plt.figure(figsize=(10, 6))
plt.barh(feature_importance['feature'][:10], feature_importance['importance'][:10])
plt.xlabel('Import√¢ncia')
plt.title('Top 10 Features Mais Importantes')
plt.gca().invert_yaxis()
plt.show()
```

---

## üìù Git e Controle de Vers√£o

### 1. Commits Frequentes e Descritivos

‚úÖ **BOM:**
```bash
git commit -m "feat: Adiciona an√°lise de correla√ß√£o entre features num√©ricas"
git commit -m "fix: Corrige tratamento de valores faltantes em internet_quality"
git commit -m "docs: Atualiza documenta√ß√£o da fun√ß√£o de pr√©-processamento"
```

‚ùå **RUIM:**
```bash
git commit -m "update"
git commit -m "fixes"
git commit -m "stuff"
```

### 2. Padr√µes de Mensagem de Commit

Use prefixos claros:
- `feat:` - Nova funcionalidade
- `fix:` - Corre√ß√£o de bug
- `docs:` - Mudan√ßas na documenta√ß√£o
- `refactor:` - Refatora√ß√£o de c√≥digo
- `test:` - Adi√ß√£o/modifica√ß√£o de testes
- `style:` - Formata√ß√£o, espa√ßos, etc.

### 3. Estrutura de Branches

```bash
# Branch de trabalho semanal
semana/1-analise-exploratoria
semana/2-preprocessamento-baseline
semana/3-modelos-avancados
semana/4-otimizacao-final

# Nunca commitar diretamente na main!
```

---

## ‚ö†Ô∏è Erros Comuns a Evitar

### 1. Data Leakage
‚ùå Usar dados de teste durante o treinamento
‚ùå Normalizar antes de fazer train-test split
‚ùå Feature engineering usando informa√ß√µes do futuro

### 2. Overfitting
‚ùå Modelo muito complexo para poucos dados
‚ùå N√£o usar valida√ß√£o cruzada
‚ùå Otimizar hiperpar√¢metros no conjunto de teste

### 3. Underfitting
‚ùå Modelo muito simples para o problema
‚ùå Features irrelevantes ou mal processadas
‚ùå N√£o fazer feature engineering

### 4. Organiza√ß√£o
‚ùå Notebooks gigantes sem estrutura
‚ùå C√≥digo sem coment√°rios
‚ùå Arquivos com nomes gen√©ricos (`teste.ipynb`, `final_final_v2.ipynb`)

---

## ‚úÖ Checklist Final

Antes de abrir seu Pull Request, verifique:

- [ ] Notebook executa do in√≠cio ao fim sem erros (`Restart & Run All`)
- [ ] C√≥digo est√° comentado adequadamente
- [ ] Visualiza√ß√µes t√™m t√≠tulos, labels e legendas
- [ ] Resultados est√£o interpretados (n√£o apenas n√∫meros)
- [ ] Commits foram feitos regularmente (n√£o apenas 1 commit)
- [ ] Mensagens de commit s√£o descritivas
- [ ] `.gitignore` est√° funcionando (nenhum arquivo grande commitado)
- [ ] README est√° atualizado (se necess√°rio)
- [ ] Dados processados salvos em `data/processed/`
- [ ] Nenhum hardcoded path absoluto (use caminhos relativos)

---

**√öltima atualiza√ß√£o:** Outubro 2027
